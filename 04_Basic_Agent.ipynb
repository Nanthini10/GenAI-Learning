{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc44234-6372-4d55-aa61-6d9107638ad8",
   "metadata": {},
   "source": [
    "# Building an Agent\n",
    "Based on: https://python.langchain.com/docs/tutorials/agents/ \n",
    "\n",
    "## Setup\n",
    "Get the API keys for LangChain, TAVILY (search engine) and your API of choice (ChatNVIDIA, in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166c770a-e858-4a0a-b46a-912bdb781d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\n",
    "# !pip install -qU langchain-openai\n",
    "!pip install -qU langchain-nvidia-ai-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bdd014-2a3a-419c-961e-6ae59beee88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LANGCHAIN_TRACING_V2=\"true\"\n",
    "!export LANGCHAIN_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e75300-309e-4199-9d68-ca0430df7997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8268f269-be09-49f2-8963-7ac41dd8d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c73d03-c0ad-4fb1-a0a3-aa0f0f3abd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1734542830, 'localtime': '2024-12-18 09:27'}, 'current': {'last_updated_epoch': 1734542100, 'last_updated': '2024-12-18 09:15', 'temp_c': 7.4, 'temp_f': 45.4, 'is_day': 1, 'condition': {'text': 'Fog', 'icon': '//cdn.weatherapi.com/weather/64x64/day/248.png', 'code': 1135}, 'wind_mph': 5.4, 'wind_kph': 8.6, 'wind_degree': 40, 'wind_dir': 'NE', 'pressure_mb': 1027.0, 'pressure_in': 30.33, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 98, 'cloud': 100, 'feelslike_c': 6.0, 'feelslike_f': 42.8, 'windchill_c': 6.0, 'windchill_f': 42.8, 'heatindex_c': 7.4, 'heatindex_f': 45.4, 'dewpoint_c': 6.9, 'dewpoint_f': 44.4, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.5, 'gust_mph': 9.8, 'gust_kph': 15.7}}\"}, {'url': 'https://www.msn.com/en-us/weather/topstories/december-18-2024-san-francisco-bay-area-weather-forecast/vi-AA1w5qHG', 'content': 'December 18, 2024 San Francisco Bay Area weather forecast. Posted: December 18, 2024 | Last updated: December 18, 2024. KRON4 Meteorologist John Shrable has the latest weather outlook. <a href'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults(max_results=2)\n",
    "search_results = search.invoke(\"what is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4621a-a5aa-4fde-88e7-d7fb6298796f",
   "metadata": {},
   "source": [
    "## Selecting and LLM\n",
    "We will use NVIDIA models to build our Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db5d630-9042-4d9c-9918-ffe9c1acda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for NVIDIA:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
    "  os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA: \")\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-70b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed8e040-9160-4731-867d-f748293ac3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f985954a-8533-4986-bfb6-b809ecca7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='mistralai/mistral-large-2-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n",
      "id='meta/llama-3.1-405b-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n",
      "id='meta/llama-3.2-3b-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n",
      "id='meta/llama-3.1-70b-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n",
      "id='nv-mistralai/mistral-nemo-12b-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n",
      "id='meta/llama-3.1-8b-instruct' model_type='chat' client='ChatNVIDIA' endpoint=None aliases=None supports_tools=True supports_structured_output=True base_model=None\n"
     ]
    }
   ],
   "source": [
    "# Get a list of models that support tool calling\n",
    "models_list = ChatNVIDIA.get_available_models()\n",
    "for m in models_list:\n",
    "    if 'supports_tools=True' in str(m):\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6ce638-6f4a-4eda-a19b-ead1e738213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ffb59c8-4aee-4d44-9d8f-8fd8fc61cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e138b-0e5b-4282-bded-ab9c1215ce9c",
   "metadata": {},
   "source": [
    "The following is not calling the tool (because we have not created the agent. The LLM recognises that the tool needs to be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2250f41b-925d-4c28-ab8d-2f9fed9df5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather'}, 'id': 'chatcmpl-tool-1f5a1fd778fe49169668e9a35b20cb0b', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f224db-ae2b-4481-aedc-3ec4502bca17",
   "metadata": {},
   "source": [
    "## Agent Creation\n",
    "\n",
    "We will use `model` as opposed to `model_with_tools` as the binding will happen underneath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7670cf91-8424-4b7f-9b60-c5c101bd6616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05959f15-0061-4b92-a80d-f5f2ead74f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
    "\n",
    "# response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8bdf637-16eb-4ee5-b1cb-f1e62cbe051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent_executor.invoke(\n",
    "#     {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
    "# )\n",
    "# response[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841dfec-7815-470c-b81a-548f3f6f5271",
   "metadata": {},
   "source": [
    "## Memory makes the agent useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a59d813c-e041-49e8-b8c6-e1e38c296b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a43bfb40-aa10-4b31-8d5b-376657d5c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e18d08cb-5167-4ebb-94fa-73ef7bf35bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content=\"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Hi Bob! It's nice to meet you. Is there something I can help you with or would you like to chat?\", 'token_usage': {'prompt_tokens': 317, 'total_tokens': 342, 'completion_tokens': 25}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run-48b96f67-b0d7-49fe-abb1-f80c6822cf86-0', usage_metadata={'input_tokens': 317, 'output_tokens': 25, 'total_tokens': 342}, role='assistant')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55d0b4c1-2a9c-45eb-ba5c-cabcb8062c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Bob.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your name is Bob.', 'token_usage': {'prompt_tokens': 357, 'total_tokens': 362, 'completion_tokens': 5}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run-b8f6a260-6e53-4aad-be0e-839eee401160-0', usage_metadata={'input_tokens': 357, 'output_tokens': 5, 'total_tokens': 362}, role='assistant')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801745d-ee7c-4b7d-92ca-c6e68555e8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
